{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='black'>Регрессионный анализ социально-экономических процессов, 2024 - 2025 </font>\n",
        "## <font color='black'> Модели бинарного выбора </font>\n",
        "В рамках данного практического занятия мы потренируемся в оценивании и интерпретации оценок моделей бинарного выбора. По мотивам статьи [Joan Esteban, Laura Mayoral, Debraj Ray \"Ethnicity and Conflict: an Empirical Study\"\n",
        "American Economic Review 2012, 102(4): 1310–1342] рассмотрим зависимость степени конфликта от таких мер, как поляризация и фракционализация. Ниже представлено краткое описание данных:\n",
        "\n",
        "* prioInt - «Conflict intensity» from PRIO: we assign a value of 0 if there is peace in a given year, a value of 1 if there is a weak conflict in a given year,\n",
        "and a value of 2 if there is a strong conflict in a given year\n",
        "* prioIntLag - Lagged conflict intensity\n",
        "* f - Fractionalization index (data from Fearon (2003b) and the\n",
        "Ethnologue project)\n",
        "* p - Polarization index (Group shares are constructed\n",
        "as above, for f; data on language and linguistic distances come from\n",
        "Ethnologue)\n",
        "* gini - Greenberg-Gini index (Ethnologue; Fearon (2003)\n",
        "* gpd - Log of real GDP per capita\n",
        "* pop - Log of population\n",
        "* mount - Percent mountainous terrain\n",
        "* ncont - Noncontiguous states, referring to countries with territory holding at\n",
        "least 10,000 people and separated from the land area containing the\n",
        "capital city either by land or by 100 kilometers of water\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3M8dgUBkZkr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy.stats import chi2\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score"
      ],
      "metadata": {
        "id": "OqrciQvYcchz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставим в массиве только необходимые переменные для анализа. Кроме этого, перекодируем показатель степени конфликта (prioInt) в бинарный\n",
        "показатель таким образом, чтобы нулю соответствовало отсутствие конфликта,\n",
        "а единица объединяла бы две категории: «слабый конфликт» и «сильный конфликт». Выполним подобные преобразования применительно и к лагированному\n",
        "показателю (prioIntLag)"
      ],
      "metadata": {
        "id": "K5CSTmordK5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lab7 = pd.read_stata('lab_logit.dta')\n",
        "lab7 = lab7[['prioInt', 'prioIntLag', 'f', 'p', 'gini', 'gdp', 'pop', 'mount', 'ncont']].dropna()"
      ],
      "metadata": {
        "id": "FoU-L-mNdlhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab7['prioInt_labels'] = lab7['prioInt'].map({0: 'No conflict', 1: 'Weak conflict', 2: 'Strong conflict'})"
      ],
      "metadata": {
        "id": "ymUkWKWvnoCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distr = sns.countplot(x=lab7['prioInt_labels'], color = 'grey', stat = 'percent', order = lab7['prioInt_labels'].value_counts().index)\n",
        "percent = lab7['prioInt_labels'].value_counts(ascending=False, normalize=True).values * 100\n",
        "distr.bar_label(container=distr.containers[0], labels=np.round(percent,2))"
      ],
      "metadata": {
        "id": "ysC9StxFeSGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab7['prioInt_binary'] = lab7['prioInt'].apply(lambda x: 1 if x > 0 else 0)\n",
        "lab7['prioIntLag_binary'] = lab7['prioIntLag'].apply(lambda x: 1 if x > 0 else 0)"
      ],
      "metadata": {
        "id": "iZtEm68Ypg8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценим логит-модель с prioInt_binary в качестве зависимой переменной"
      ],
      "metadata": {
        "id": "P6PwSvayrwoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1_logit = smf.logit(\"prioInt_binary ~ prioIntLag_binary + f + p + gini + gdp + pop + mount + ncont\", data=lab7).fit(cov_type = \"HC3\")\n",
        "print(m1_logit.summary())"
      ],
      "metadata": {
        "id": "7cSuD9PFrvyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним полученные оценки с соответствующими оценками probit-модели (данная модель основывается на допущении о стандартном нормальном распределении ошибок)"
      ],
      "metadata": {
        "id": "CmQwIAmQsEJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1_probit = smf.probit(\"prioInt_binary ~ prioIntLag_binary + f + p + gini + gdp + pop + mount + ncont\", data=lab7).fit(cov_type = \"HC3\")\n",
        "print(m1_probit.summary())"
      ],
      "metadata": {
        "id": "qpUCOnlXsVFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit_probit_ratios = pd.DataFrame(\n",
        "    {\"logit\": round(m1_logit.params, 3),\n",
        "     \"probit\": round(m1_probit.params, 3),\n",
        "     \"logit/probit\": round(m1_logit.params/m1_probit.params, 3)}\n",
        "    )\n",
        "\n",
        "print(logit_probit_ratios)"
      ],
      "metadata": {
        "id": "MQJ4VeGnsbdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем оценки логит-модели в отношения шансов:"
      ],
      "metadata": {
        "id": "rDMBMUkRssbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "odds_ratios = pd.DataFrame(\n",
        "    {\"OR\": round(np.exp(m1_logit.params), 3),\n",
        "     \"p-value\": round(m1_logit.pvalues, 3),\n",
        "     \"Lower CI\": round(np.exp(m1_logit.conf_int()[0]),3),\n",
        "     \"Upper CI\": round(np.exp(m1_logit.conf_int()[1]),3)}\n",
        "    )\n",
        "\n",
        "print(odds_ratios)"
      ],
      "metadata": {
        "id": "iu_Ej8OsswCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также возможен вариант интерпретации оценок коэффициентов при непрерывных переменных через предельные эффекты:"
      ],
      "metadata": {
        "id": "_NfIAYaItAXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ME = m1_logit.get_margeff()\n",
        "print(ME.summary())"
      ],
      "metadata": {
        "id": "CoasOWaMtID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве предварительной диагностики модели можно использовать тест Хосмера-Лемешева (Hosmer-Lemeshow). Посредством данного теста мы сравним ожидаемые и наблюдаемые частоты по подгруппам (чаще всего берется разделение по децилям). Надо признать, что результаты теста довольно чувствительны к количеству групп, на которые делится массив данных."
      ],
      "metadata": {
        "id": "yujOPKWousYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = lab7[['prioIntLag_binary', 'f', 'p', 'gini', 'gdp', 'pop', 'mount', 'ncont']]\n",
        "y = lab7[['prioInt_binary']]"
      ],
      "metadata": {
        "id": "cahq-ZP7vcSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = m1_logit.predict(X)\n",
        "y_prob1 = pd.concat([y_prob, y], axis = 1)\n",
        "y_prob1['decile'] = pd.qcut(y_prob1[0], 10)"
      ],
      "metadata": {
        "id": "Qbp2YUMIvqvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obsevents_pos = y_prob1['prioInt_binary'].groupby(y_prob1.decile, observed = True).sum()\n",
        "obsevents_neg = y_prob1[0].groupby(y_prob1.decile, observed = True).count() - obsevents_pos\n",
        "expevents_pos = y_prob1[0].groupby(y_prob1.decile, observed = True).sum()\n",
        "expevents_neg = y_prob1[0].groupby(y_prob1.decile, observed = True).count() - expevents_pos\n",
        "decile_dataset = pd.concat([obsevents_pos, obsevents_neg, expevents_pos, expevents_neg], axis = 1)\n",
        "decile_dataset.columns=['obs_pos','obs_neg','exp_pos', 'exp_neg']\n",
        "print(decile_dataset)"
      ],
      "metadata": {
        "id": "FJbl008Owdox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hl = ((obsevents_neg - expevents_neg)**2/expevents_neg).sum()+((obsevents_pos - expevents_pos)**2/expevents_pos).sum()\n",
        "df = 8\n",
        "pvalue=1-chi2.cdf(hl,df)\n",
        "print('chi-square: {:.2f}'.format(hl))\n",
        "print('p-value: {:.2f}'.format(pvalue))"
      ],
      "metadata": {
        "id": "eOmbnMqTyDMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для лучшего понимания, насколько хорошо модель предсказывает наличие и отсутствие конфликта, представим confusion matrix:"
      ],
      "metadata": {
        "id": "L8bkx_lp2ymY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_prob1[0].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "confmatrix = confusion_matrix(y_true=lab7['prioInt_binary'], y_pred=y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confmatrix)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "4hsEvjIU3DPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = confmatrix[1][1]\n",
        "TN = confmatrix[0][0]\n",
        "FP = confmatrix[0][1]\n",
        "FN = confmatrix[1][0]\n",
        "\n",
        "Accuracy = round((TP + TN) / (TP + TN + FP + FN), 3)\n",
        "Baseline_Accuracy = round(max((TN + FP), (FN + TP)) / (TP + TN + FP + FN) , 3)\n",
        "\n",
        "Sensitivity = round(TP / (TP + FN), 3)\n",
        "Specificity = round(TN / (TN + FP), 3)\n",
        "ErrorI = round((1 - Specificity), 3)\n",
        "ErrorII = round((1-Sensitivity), 3)\n",
        "\n",
        "print('Accuracy: {:.2f}'.format(Accuracy)),\n",
        "print('Baseline_Accuracy: {:.2f}'.format(Baseline_Accuracy))\n",
        "print('Sensitivity: {:.2f}'.format(Sensitivity))\n",
        "print('Specificity: {:.2f}'.format(Specificity))\n",
        "print('ErrorI: {:.2f}'.format(ErrorI))\n",
        "print('ErrorII: {:.2f}'.format(ErrorII))"
      ],
      "metadata": {
        "id": "zTV33MUb32Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проследим, как изменяются меры чувствительности и ошибки первого рода в зависимости от выбранного порогового значения:"
      ],
      "metadata": {
        "id": "V_f8HdM58aq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y, y_prob)\n",
        "\n",
        "fig = px.area(\n",
        "    x=fpr, y=tpr,\n",
        "    title=f'ROC Curve (AUC={auc(fpr, tpr):.3f})',\n",
        "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
        "    width=700, height=500\n",
        ")\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "\n",
        "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "fig.update_xaxes(constrain='domain')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "pnruq62l6Z3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'Specificity': 1-fpr,\n",
        "    'Sensitivity': tpr\n",
        "}, index=thresholds)\n",
        "df.index.name = \"Thresholds\"\n",
        "df.columns.name = \"Rate\"\n",
        "\n",
        "fig_thresh = px.line(\n",
        "    df, title='Sensitivity and Specificity at different thresholds',\n",
        "    width=700, height=500\n",
        ")\n",
        "\n",
        "fig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=0.75)\n",
        "fig_thresh.update_xaxes(range=[0, 1], constrain='domain')\n",
        "fig_thresh.show()"
      ],
      "metadata": {
        "id": "vKgTSaEU7Vwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим порог, при котором значения специфичности и чувствительности будут сбалансированы:"
      ],
      "metadata": {
        "id": "f6BhGZxU7wzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff = np.abs(tpr-(1-fpr))\n",
        "min_diff = np.argmin(diff)\n",
        "\n",
        "optimized_threshold = thresholds[min_diff]\n",
        "\n",
        "optimized_threshold"
      ],
      "metadata": {
        "id": "7s8UIFxY74i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переоцените модель при заданном пороговом значении (optimized_threshold) и прокомментируйте, как изменились меры качества модели"
      ],
      "metadata": {
        "id": "QsCovKBP8F2T"
      }
    }
  ]
}